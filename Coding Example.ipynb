{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "from sklearn import preprocessing\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hololive_us = pd.read_csv('hololive_us.csv', header=1)\n",
    "hololive_katakana_jp = pd.read_csv('hololive_katakana_jp.csv', header=1)\n",
    "hololive_us.info()\n",
    "hololive_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_google_trends(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Turns 0's from strings to ints and\n",
    "    <1's to 1 (int)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.replace('<1', 1)\n",
    "    df = df.replace('0', 0)\n",
    "    df['Week'] = pd.to_datetime(df['Week'], format='%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "clean_us = clean_google_trends(hololive_us)\n",
    "clean_jp = clean_google_trends(hololive_katakana_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_plot = plt.plot(clean_us['Week'], clean_us['hololive: (United States)'], color='red', label='US')\n",
    "google_plot = plt.plot(clean_us['Week'], clean_jp['ホロライブ: (Japan)'], color='skyblue', label='JP (katakana)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Hololive US & Japan Youtube Popularity (Japanese katakana)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "def scrape_playlist(playlist_link, driver_location, file_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Script to scrape titles and account names from a youtube playlist link using selenium\n",
    "    Saves to csv.\n",
    "    \n",
    "    Must use msedge driver from selenium and input local file pathway as driver_location\n",
    "    \"\"\"\n",
    "    \n",
    "    driver = webdriver.Edge(driver_location)\n",
    "    driver.get(playlist_link)\n",
    "    driver.maximize_window()\n",
    "    body = driver.find_element_by_css_selector('body')\n",
    "    \n",
    "    ## Get playlist length to determine how many times need to scroll before getting to bottom of page\n",
    "    ## Approx. 100 videos per load\n",
    "    video_count = int(driver.find_element_by_xpath('//*[@id=\"stats\"]/yt-formatted-string[1]/span[1]'))\n",
    "    scrolls = int((video_count + 100)/100)\n",
    "    \n",
    "    ## Scroll to bottom of page\n",
    "    for i in range(scrolls):\n",
    "        body.send_keys(Keys.END)\n",
    "        time.sleep(3)\n",
    "        print(f'[{i/scrolls}] Loading...')\n",
    "    \n",
    "    ## Scrape titles, channels, thumbnails\n",
    "    print('Getting titles...')\n",
    "    titles = driver.find_elements_by_id('video-title')\n",
    "    print('Getting accounts...')\n",
    "    channels = driver.find_elements_by_xpath('//*[@id=\"text\"]/a')\n",
    "    channels.pop(0) #\n",
    "    print('Getting thumbnails')\n",
    "    thumbnails = driver.find_elements_by_id('img')\n",
    "    \n",
    "    df = pd.DataFrame([i.text for i in titles], [i.text for i in channels], [i.get_attrivute('src') for i in thumbnails])\n",
    "    df.to_csv(f'{file_name}.csv')\n",
    "    print(f'{file_name}.csv saved')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vtuber_playlist.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_by = df[['account', 'title']].groupby('account').count()\n",
    "grp_by_sorted = grp_by.sort_values('title', ascending=False)\n",
    "grp_by_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_by_selected = grp_by_sorted.iloc[1:, :]\n",
    "sns.displot(data=grp_by_selected, binwidth=1, stat='percent')\n",
    "plt.title('Count of Repeated Accounts Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title char count'] = [len(i) for i in df['title']]\n",
    "df['account char count'] = [len(i) for i in df['account']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.displot(data=df['title char count'], color='skyblue', binwidth=5)\n",
    "plt.axvline(x=df['title char count'].mean(),\n",
    "            color='red')\n",
    "sns.displot(data=df['account char count'], color='coral')\n",
    "plt.axvline(x=df['account char count'].mean(),\n",
    "           color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_char = df['title char count']\n",
    "account_char = df['account char count']\n",
    "title_char_norm = preprocessing.normalize([title_char], norm='max')\n",
    "account_char_norm = preprocessing.normalize([account_char], norm='max')\n",
    "norm = np.array([title_char_norm[0], account_char_norm[0]]).T\n",
    "char_norm = pd.DataFrame(norm, columns=['title', 'account'])\n",
    "char_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.displot(data=char_norm['title'], color='skyblue')\n",
    "sns.displot(data=char_norm['account'], color='coral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df, x='title char count', y='account char count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Function to clean an individual string\n",
    "    \"\"\"\n",
    "    \n",
    "    return text.replace('【', '').replace('】', '').replace('[', ' ').replace(']', ' ').replace('/' , ' and ').lower()\n",
    "\n",
    "def filter_text(text):\n",
    "    \"\"\"\n",
    "    Function to get rid of stopwords in a list of words\n",
    "    \"\"\"\n",
    "    \n",
    "    return [i for i in text if i not in stopwords.words('english')]\n",
    "\n",
    "def filter_clean_text(text):\n",
    "    \"\"\"\n",
    "    Combine text cleaning and filtering functions\n",
    "    \"\"\"\n",
    "    \n",
    "    x = text.replace('【', ' ').replace('】', ' ').replace('[', ' ').replace(']', ' ').replace('/' , ' and ')\n",
    "    x = text.replace('eng', '').replace('english', '').replace('hololive', '').lower()\n",
    "    return [i for i in x.split() if i not in stopwords.words('english')]\n",
    "\n",
    "title_text_cleaned = clean_text(' '.join(df['title'])).split()\n",
    "title_text_filtered = filter_text(title_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stopped = collections.Counter(title_text_filtered).most_common(10)\n",
    "common_before = collections.Counter(title_text_cleaned).most_common(10)\n",
    "common_before, common_stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[filter_clean_text(sentence) for sentence in df['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title']\n",
    "asdf = collections.Counter(titles[2].split())\n",
    "grp_by = df[['account', 'title']].groupby('account').count().sort_values('title', ascending=False)\n",
    "\n",
    "' '.join(df['title']).split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
